{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:101: DeprecationWarning: FancyURLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraper application for gathering data about pollution in Madrid\n",
      "Data by stations[1], contaminant[2], or both [3]\n",
      "Quit[Q]\n",
      ">3\n",
      "\n",
      "\n",
      "Datos por estación y contaminante\n",
      "Seleccione la estación: \n",
      "(0, 'PLAZA ESPAÑA')\n",
      "(1, 'ESCUELAS AGUIRRE')\n",
      "(2, 'AVDA. RAMON Y CAJAL')\n",
      "(3, 'ARTURO SORIA')\n",
      "(4, 'VILLAVERDE')\n",
      "(5, 'FAROLILLO')\n",
      "(6, 'CASA DE CAMPO')\n",
      "(7, 'BARAJAS PUEBLO')\n",
      "(8, 'PLAZA DEL CARMEN')\n",
      "(9, 'MORATALAZ')\n",
      "(10, 'CUATRO CAMINOS')\n",
      "(11, 'BARRIO DEL PILAR')\n",
      "(12, 'PUENTE DE VALLECAS')\n",
      "(13, 'MENDEZ ALVARO')\n",
      "(14, 'CASTELLANA')\n",
      "(15, 'RETIRO')\n",
      "(16, 'PLAZA DE CASTILLA')\n",
      "(17, 'ENSANCHE DE VALLECAS')\n",
      "(18, 'URBANIZACION EMBAJADA')\n",
      "(19, 'PLAZA ELÍPTICA')\n",
      "(20, 'SANCHINARRO')\n",
      "(21, 'EL PARDO')\n",
      "(22, 'JUAN CARLOS I')\n",
      "(23, 'TRES OLIVOS')\n",
      ">6\n",
      "Seleccione el contaminante: \n",
      "(0, 'PM10')\n",
      "(1, 'PM2.5')\n",
      "(2, 'SO2')\n",
      "(3, 'CO')\n",
      "(4, 'O3')\n",
      "(5, 'NO2')\n",
      "(6, 'BEN')\n",
      "(7, 'TOL')\n",
      ">0\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Los sensores de PM10 en CASA DE CAMPO indican:\n",
      "1  µg/m³\n",
      "---------------------------------\n",
      "Data may be affected by further validation.\n",
      "Last hour data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web scraper application for gathering data about pollution in Madrid\n",
      "Data by stations[1], contaminant[2], or both [3]\n",
      "Quit[Q]\n",
      ">1\n",
      "\n",
      "\n",
      "Datos por estación\n",
      "Seleccione la estación: \n",
      "(0, 'PLAZA ESPAÑA')\n",
      "(1, 'ESCUELAS AGUIRRE')\n",
      "(2, 'AVDA. RAMON Y CAJAL')\n",
      "(3, 'ARTURO SORIA')\n",
      "(4, 'VILLAVERDE')\n",
      "(5, 'FAROLILLO')\n",
      "(6, 'CASA DE CAMPO')\n",
      "(7, 'BARAJAS PUEBLO')\n",
      "(8, 'PLAZA DEL CARMEN')\n",
      "(9, 'MORATALAZ')\n",
      "(10, 'CUATRO CAMINOS')\n",
      "(11, 'BARRIO DEL PILAR')\n",
      "(12, 'PUENTE DE VALLECAS')\n",
      "(13, 'MENDEZ ALVARO')\n",
      "(14, 'CASTELLANA')\n",
      "(15, 'RETIRO')\n",
      "(16, 'PLAZA DE CASTILLA')\n",
      "(17, 'ENSANCHE DE VALLECAS')\n",
      "(18, 'URBANIZACION EMBAJADA')\n",
      "(19, 'PLAZA ELÍPTICA')\n",
      "(20, 'SANCHINARRO')\n",
      "(21, 'EL PARDO')\n",
      "(22, 'JUAN CARLOS I')\n",
      "(23, 'TRES OLIVOS')\n",
      ">10\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "PM10 4 µg/m³\n",
      "PM2.5 1 µg/m³\n",
      "SO2 9 µg/m³\n",
      "CO - mg/m³\n",
      "O3 - µg/m³\n",
      "NO2 14 µg/m³\n",
      "BEN 0.20 µg/m³\n",
      "TOL 0.60 µg/m³\n",
      "---------------------------------\n",
      "Data may be affected by further validation.\n",
      "Last hour data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web scraper application for gathering data about pollution in Madrid\n",
      "Data by stations[1], contaminant[2], or both [3]\n",
      "Quit[Q]\n",
      ">2\n",
      "\n",
      "\n",
      "Datos un contaminante para todas las estaciones disponibles\n",
      "Seleccione el contaminante: \n",
      "(0, 'PM10')\n",
      "(1, 'PM2.5')\n",
      "(2, 'SO2')\n",
      "(3, 'CO')\n",
      "(4, 'O3')\n",
      "(5, 'NO2')\n",
      "(6, 'BEN')\n",
      "(7, 'TOL')\n",
      ">3\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Los sensores de CO indican:\n",
      "PLAZA ESPAÑA: 0.30 mg/m³\n",
      "ESCUELAS AGUIRRE: 0.10 mg/m³\n",
      "AVDA. RAMON Y CAJAL: - mg/m³\n",
      "ARTURO SORIA: 0.30 mg/m³\n",
      "VILLAVERDE: - mg/m³\n",
      "FAROLILLO: 0.30 mg/m³\n",
      "CASA DE CAMPO: 0.20 mg/m³\n",
      "BARAJAS PUEBLO: - mg/m³\n",
      "PLAZA DEL CARMEN: 0.30 mg/m³\n",
      "MORATALAZ: 0.20 mg/m³\n",
      "CUATRO CAMINOS: - mg/m³\n",
      "BARRIO DEL PILAR: 0.20 mg/m³\n",
      "PUENTE DE VALLECAS: - mg/m³\n",
      "MENDEZ ALVARO: - mg/m³\n",
      "CASTELLANA: - mg/m³\n",
      "RETIRO: - mg/m³\n",
      "PLAZA DE CASTILLA: - mg/m³\n",
      "ENSANCHE DE VALLECAS: - mg/m³\n",
      "URBANIZACION EMBAJADA: - mg/m³\n",
      "PLAZA ELÍPTICA: 0.30 mg/m³\n",
      "SANCHINARRO: 0.20 mg/m³\n",
      "EL PARDO: - mg/m³\n",
      "JUAN CARLOS I: - mg/m³\n",
      "TRES OLIVOS: - mg/m³\n",
      "---------------------------------\n",
      "Data may be affected by further validation.\n",
      "Last hour data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Web scraper application for gathering data about pollution in Madrid\n",
      "Data by stations[1], contaminant[2], or both [3]\n",
      "Quit[Q]\n",
      ">q\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "# display\n",
    "def pintar():\n",
    "    print(\"\\n\")\n",
    "    print(contaminants)\n",
    "    print(stations)\n",
    "    print(pollution)\n",
    "    \n",
    "def input_station():\n",
    "    print(\"Seleccione la estación: \")\n",
    "    for i in enumerate(stations):\n",
    "        print(i)\n",
    "    a = int(input(\">\"))\n",
    "    return a\n",
    "\n",
    "def input_cont():\n",
    "    print(\"Seleccione el contaminante: \")\n",
    "    for i in enumerate(contaminants):\n",
    "        print(i)\n",
    "    \n",
    "    b = int(input(\">\"))\n",
    "    return b\n",
    "\n",
    "def uds(s):\n",
    "    if(s=='CO'):\n",
    "        uds = \" mg/m³\"\n",
    "    else:\n",
    "        uds = \" µg/m³\"\n",
    "    return uds\n",
    "def begining():\n",
    "    print(\"\\n\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "def ending():\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Data may be affected by further validation.\")\n",
    "    print(\"Last hour data.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def switch(n):\n",
    "    if n == 3:\n",
    "        station_contaminant()\n",
    "    elif n ==1:\n",
    "        stations_()\n",
    "    elif n ==2:\n",
    "        cont_()\n",
    "\n",
    "def station_contaminant():\n",
    "    print(\"\\n\")\n",
    "    print(\"Datos por estación y contaminante\")\n",
    "    a = input_station()\n",
    "    b = input_cont() \n",
    "    begining()\n",
    "    print(\"Los sensores de \" + contaminants[b] + \" en \" + stations[a] + \" indican:\")\n",
    "    ud = uds(contaminants[b])\n",
    "    pol = pollution[stations[a]][contaminants[b]]\n",
    "    print(pol + \" \" + ud)\n",
    "    ending()\n",
    "\n",
    "def stations_():    \n",
    "    print(\"\\n\")\n",
    "    print(\"Datos por estación\")\n",
    "    a = input_station()\n",
    "    pol = pollution[stations[a]]\n",
    "    begining()\n",
    "    for k in pol:\n",
    "        print(k + \" \" + pol[k] + uds(k))\n",
    "    ending()\n",
    "\n",
    "def cont_():\n",
    "    print(\"\\n\")\n",
    "    print(\"Datos un contaminante para todas las estaciones disponibles\")\n",
    "    b = input_cont()\n",
    "    begining()\n",
    "    print(\"Los sensores de \" + contaminants[b] + \" indican:\")\n",
    "    for k in pollution:\n",
    "        print (k + \": \" + pollution[k][contaminants[b]] + uds(contaminants[b]))\n",
    "    ending()\n",
    "#fields of interest\n",
    "contaminants = []\n",
    "stations = []\n",
    "pollution = {}\n",
    "\n",
    "# regex utils\n",
    "preStat =\"<td class=\\\"primertd\\\" headers=\\\"Estación\\\">\"\n",
    "postStat= \"</td>\"\n",
    "preRow = \"<td headers=\\\"\"\n",
    "postRow = \"</td>\"\n",
    "preCont =\"<th style=\\\"width:45px\\\" id=\\\"\"\n",
    "postCont =\"\\\">\"\n",
    "\n",
    "# urls\n",
    "# url_madrid = \"http://www.mambiente.madrid.es/opencms/opencms/calaire/consulta/Gases_y_particulas/informegaseshorarios.html?__locale=es\"\n",
    "url_madrid2 = \"http://www.mambiente.madrid.es/opencms/opencms/calaire/consulta/Gases_y_particulas/informegaseshorarios_antiguo.html?__locale=es\"\n",
    "\n",
    "\n",
    "# open url in file\n",
    "opener = urllib.request.FancyURLopener({})\n",
    "with opener.open(url_madrid2) as f:\n",
    "    # print(f.read().decode('utf-8'))\n",
    "    lines = f.read().decode('utf8').splitlines()\n",
    "f.close()\n",
    "\n",
    "# search for stations and contamintants available\n",
    "for line in lines:\n",
    "    q = re.findall('(?<=' + preCont + ').*?(?=' + postCont + ')', line)\n",
    "    if(q != []):\n",
    "        contaminants.append(q[0])\n",
    "    q = re.findall('(?<=' + preStat + ').*?(?=' + postStat + ')', line)   \n",
    "    if(q != [] and q[0] != '&nbsp;' ):\n",
    "        stations.append(q[0])\n",
    "        # pollution[q[0]]=[]\n",
    "        pollution[q[0]]={}\n",
    "\n",
    "# let's go find the pollution\n",
    "i=0\n",
    "j=0\n",
    "o=True\n",
    "while(o):\n",
    "    q = re.findall('(?<=' + preStat + str(stations[i]) + postStat + ').*?(?=' +  ')', lines[j])\n",
    "    if(q != [] and q[0] != '&nbsp;'):\n",
    "        j+=2\n",
    "        l=0\n",
    "        for k in range(15): # 15\n",
    "            j+=1\n",
    "            s = re.findall('(?<=' + preRow + contaminants[l] + '\\\">' + ').*?(?=' + postRow +  ')', lines[j])\n",
    "            if(s!=[]):\n",
    "                #pollution[stations[i]].append({contaminants[l] : s[0]})\n",
    "                pollution[stations[i]][contaminants[l]] = s[0]\n",
    "                l+=1\n",
    "        #o=False\n",
    "        i+=1\n",
    "    j+=1\n",
    "    if(j>600): o = False\n",
    "\n",
    "\n",
    "#pintar()\n",
    "# main interaction:\n",
    "def main():\n",
    "    o = True\n",
    "    while(o):\n",
    "        \n",
    "        print(\"Web scraper application for gathering data about pollution in Madrid\")\n",
    "        print(\"Data by stations[1], contaminant[2], or both [3]\")\n",
    "        print (\"Quit[Q]\")\n",
    "        k = input(\">\")\n",
    "        if k=='q' or k =='Q':\n",
    "            o = False\n",
    "        else:\n",
    "            switch(int(k))\n",
    "        print(\"\\n\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
